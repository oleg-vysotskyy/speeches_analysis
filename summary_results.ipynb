{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaudrzP9Vr79vUvJTSP/E+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oleg-vysotskyy/speeches_analysis/blob/main/summary_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auvzGGo2JA7f",
        "outputId": "b7e167f4-722a-4793-d0f0-3cc1b9359e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/Speakers/Harris_all_speeches_results.txt\n",
            "Summarized JSON saved to: /content/drive/My Drive/Colab Notebooks/Speakers/Harris_all_speeches_results.json\n",
            "/content/drive/My Drive/Colab Notebooks/Speakers/Trump_all_speeches_results.txt\n",
            "Summarized JSON saved to: /content/drive/My Drive/Colab Notebooks/Speakers/Trump_all_speeches_results.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "#drive.flush_and_unmount()\n",
        "\n",
        "#file_path = \"/Users/oleg_vysotskyy/Documents/Work/Python/\"\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/Speakers/\"\n",
        "os.chdir(file_path)\n",
        "\n",
        "# File path input\n",
        "file_names_input = [\"Harris_all_speeches_results.txt\", \"Trump_all_speeches_results.txt\"]\n",
        "\n",
        "# change directory\n",
        "#my_directory = \"/Users/oleg_vysotskyy/Documents/Work/Python\"\n",
        "#file_path = os.getcwd()\n",
        "#os.chdir(my_directory)\n",
        "#print(file_path)\n",
        "\n",
        "# Process the file\n",
        "for element in file_names_input:\n",
        "    summary = {\n",
        "        \"Sentiment Counts\": Counter(),\n",
        "        \"Topics\": Counter(),\n",
        "        \"Total Word Count\": 0,\n",
        "        \"Pronouns\": Counter(),\n",
        "        \"Nouns\": Counter(),\n",
        "        \"Adjectives\": Counter(),\n",
        "        \"Average Sentence Types\": defaultdict(float),\n",
        "        \"Repetition Count\": 0,\n",
        "        \"Total Speeches\": 0\n",
        "    }\n",
        "    element = file_path + element\n",
        "    print(element)\n",
        "    with open(element, 'r') as file:\n",
        "        # Split into individual JSON blocks\n",
        "        data_blocks = file.read().split('```json')[1:]\n",
        "\n",
        "        # Loop through each JSON block\n",
        "        for block in data_blocks:\n",
        "            json_str = block.split('```')[0].strip()  # Extract JSON string\n",
        "            json_data = json.loads(json_str)  # Parse JSON\n",
        "\n",
        "            # Update summary\n",
        "            summary[\"Sentiment Counts\"][json_data[\"Sentiment\"]] += 1\n",
        "            summary[\"Topics\"].update(json_data[\"Topics\"])\n",
        "            summary[\"Total Word Count\"] += json_data[\"Word count\"]\n",
        "            summary[\"Pronouns\"].update(json_data[\"Pronouns\"])\n",
        "            summary[\"Nouns\"].update(json_data[\"Nouns\"])\n",
        "            summary[\"Adjectives\"].update(json_data[\"Adjectives\"])\n",
        "            summary[\"Repetition Count\"] += 1 if json_data.get(\"Repetition\", False) else 0\n",
        "\n",
        "            for sentence_type, count in json_data[\"Types of sentences\"].items():\n",
        "                summary[\"Average Sentence Types\"][sentence_type] += count\n",
        "\n",
        "            summary[\"Total Speeches\"] += 1\n",
        "\n",
        "    # Finalize averages\n",
        "#    num_speeches = len(data_blocks)\n",
        "    for sentence_type in summary[\"Average Sentence Types\"]:\n",
        "        summary[\"Average Sentence Types\"][sentence_type] /= summary[\"Total Speeches\"]\n",
        "\n",
        "    # Convert counters to standard dicts for JSON serialization\n",
        "    summary[\"Sentiment Counts\"] = dict(summary[\"Sentiment Counts\"])\n",
        "    summary[\"Topics\"] = dict(summary[\"Topics\"])\n",
        "    summary[\"Pronouns\"] = dict(summary[\"Pronouns\"])\n",
        "    summary[\"Nouns\"] = dict(summary[\"Nouns\"])\n",
        "    summary[\"Adjectives\"] = dict(summary[\"Adjectives\"])\n",
        "    summary[\"Average Sentence Types\"] = dict(summary[\"Average Sentence Types\"])\n",
        "\n",
        "    # Save summarized JSON\n",
        "    original_file = element\n",
        "    output_path = os.path.splitext(original_file)[0] + \".json\"\n",
        "    with open(output_path, \"w\") as output_file:\n",
        "        json.dump(summary, output_file, indent=4)\n",
        "\n",
        "    print(f\"Summarized JSON saved to: {output_path}\")\n"
      ]
    }
  ]
}